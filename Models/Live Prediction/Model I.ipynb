{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3274,"status":"ok","timestamp":1651731043927,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"},"user_tz":-330},"id":"fpzLlMuEl0aA"},"outputs":[],"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers import BatchNormalization\n","from keras.models import Model\n","from keras.layers import Dropout\n","from keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9698,"status":"ok","timestamp":1651731053620,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"},"user_tz":-330},"id":"odLh_Vu6l1Ga","outputId":"62c1e568-aa85-4282-ac4e-2c9ebd5a4093"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651731053621,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"},"user_tz":-330},"id":"SDGzu9nil57E"},"outputs":[],"source":["img_width, img_height = 150, 150"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lX93EbQ5mC2P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651731055863,"user_tz":-330,"elapsed":2247,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"}},"outputId":"cb725317-8ef5-418e-f2be-8193b6b4c5ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," global_average_pooling2d (G  (None, 256)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 64)                16448     \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                528       \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 1,754,561\n","Trainable params: 19,073\n","Non-trainable params: 1,735,488\n","_________________________________________________________________\n","None\n"]}],"source":["from keras.applications import vgg16\n","\n","#base_model = tf.keras.applications.MobileNetV2(input_shape=(150, 150, 3),include_top=False,weights='imagenet')\n","\n","base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","def addTopOnNet(bottom_model, num_classes):\n","    top_model = bottom_model.get_layer(\"block3_pool\").output\n","    top_model = GlobalAveragePooling2D()(top_model)\n","    top_model = Dense(64,activation='relu')(top_model)\n","    top_model = Dropout(0.4)(top_model)\n","    top_model = Dense(32,activation='relu')(top_model)\n","    top_model = Dropout(0.4)(top_model)\n","    top_model = Dense(16,activation='relu')(top_model)\n","    top_model = Dropout(0.4)(top_model)\n","    top_model = Dense(num_classes,activation='sigmoid')(top_model)\n","    return top_model\n","\n","FC_Head = addTopOnNet(base_model, 1)\n","\n","model = Model(inputs = base_model.input, outputs = FC_Head)\n","\n","print(model.summary())"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651731055863,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"},"user_tz":-330},"id":"7Qt63oJJmO8E"},"outputs":[],"source":["model.load_weights('/content/drive/MyDrive/Final year project/CNN_test/Test_Video/weights/model00000005.h5')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651731055864,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"},"user_tz":-330},"id":"9u3paxYymdNA"},"outputs":[],"source":["import cv2\n","import numpy as np\n","trained_face_data = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","\n","def get_face(image):\n","    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    face_coordinates = trained_face_data.detectMultiScale(gray_img)\n","    try:\n","        y, x, h, w = face_coordinates[0]\n","        return face_coordinates[0], image[x: x + w + 1, y: y + h + 1, :]\n","    except:\n","        return False, 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YXiLkbm1mzot"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","cap = cv2.VideoCapture('/content/drive/MyDrive/Final year project/CNN_test/Test_Video/merge.mp4')\n","\n","alpha = 0.1\n","ewma = -1\n","# i = 0\n","# k = 100\n","\n","RED = np.array([0, 0, 255])\n","GREEN = np.array([0, 255, 0])\n","\n","out = None\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","codec = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(\"output.mp4\", codec, fps, (width, height))\n","\n","while(cap.isOpened()):\n","    ret, frame = cap.read()\n","    if ret:\n","        val, face = get_face(frame)\n","        if type(val) == bool:\n","            out.write(frame)\n","            continue\n","        face = cv2.resize(face, (img_width, img_height))\n","        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n","        t = np.array([face]) / 255.\n","        curr = model.predict(t)[0][0]\n","        ewma = curr if ewma == -1 else curr * alpha + (1 - alpha) * ewma\n","        #print(curr, ewma)\n","        color = tuple(GREEN * (ewma) + RED * (1 - ewma))\n","        frame = cv2.rectangle(frame, (val[0], val[1]), (val[0] + val[2], val[1] + val[3]), color, 2)\n","        frame = cv2.putText(frame, str(ewma)[:4], (0, 30), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, color, 2)\n","        out.write(frame)\n","        #cv2_imshow(frame)\n","        print(curr, ewma)\n","\n","    else:\n","        break\n","\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xwlx1n5yZKTM","executionInfo":{"status":"aborted","timestamp":1651731085392,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aditya Dhane","userId":"13273099324321668952"}}},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"video.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}